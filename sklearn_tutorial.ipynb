{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn Introductory Tutorial\n",
    "\n",
    "[scikit-learning](http://scikit-learn.org/stable/index.html) is an open-sourced simple and efficient tools for data mining, data analysis and machine learning in Python. It is built on NumPy, SciPy and matplotlib. There are built-in classification, regression, and clustering models, as well as useful features like dimensionality reduction, evaluation and preprocessing. \n",
    "\n",
    "This tutorial is specifically tailored for NLP, i.e. working with text data. It will cover the following topics: loading data, preprocessing, feature extraction, training, evaluation, grid search, building a pipeline, creating custom transformers, etc.\n",
    "\n",
    "For this tutorial, we will use the [20 Newsgroups data set](http://qwone.com/~jason/20Newsgroups/) and perform topic classification. For the sake of time, I converted all the data into a CSV file. \n",
    "\n",
    "Note: apparently Jupyter disables spell-checker, so I'm only partially responsible for the typos in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Dataset\n",
    "\n",
    "For the sake of convenience, we will use pandas to read CSV file. (You may do so with numpy as well; there is a `loadtext()` function, but you might encounter encoding issues when using it. The dataset is compressed into a tarball, so in the termal run ``tar xvfz 20news-18828.csv.tar.gz`` to uncompress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('20news-18828.csv', header=None, delimiter=',', names=['label', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 categories: True\n",
      "There are 18828 records: True\n"
     ]
    }
   ],
   "source": [
    "print(\"There are 20 categories: %s\" % (len(dataset.label.unique()) == 20))\n",
    "print(\"There are 18828 records: %s\" % (len(dataset) == 18828))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split it to train set and test set. To do so, we can use the `train_test_split()` function. In scikit-learn's convention, X indicates data (yeah, uppercase X), and y indicates truths (and yeah, lowercase y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.text, dataset.label, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A Simple Example\n",
    "\n",
    "Before going too much into preprocessing, feature extraction and other more complicated tasks, we will do a relatively simple but complete example. In this example, we will use bag-of-words as features, and Naive Bayes as classifier to establish our baseline.\n",
    "\n",
    "There are some built-in vectorizers, `CountVectorizer` and `TfidfVectorizer` that we can use to vectorizer our raw data and perform preprocessing and feature exctration on it. First, we will experiment with `CountVectorizer` which basically makes a token/ngram a feature and stores its count in the corresponding feature space. The `fit_transform()` function is the combination of `fit()` and `transform()`. `fit()` learns the vocabulary/features of a document, and `transform()` transforms the dataset into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15062, 181850)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# initialize a CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# fit the raw data into the vectorizer and tranform it into a series of arrays\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar thing needs to be done for the test set, but we only need to use the `transform()` function to transform the test data into a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3766, 181850)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = cv.transform(X_test)\n",
    "X_test_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we fit our features and labels into a Naive Bayes classifier, which basically trains a model (if you fit the data more than once, it overwrites the parameters the model learns previously). After training, we can use it to perform prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.electronics sci.electronics\n",
      "comp.windows.x comp.windows.x\n",
      "rec.motorcycles rec.motorcycles\n",
      "talk.politics.mideast talk.politics.mideast\n",
      "comp.windows.x comp.windows.x\n",
      "rec.sport.hockey rec.sport.baseball\n",
      "sci.crypt sci.crypt\n",
      "rec.autos rec.autos\n",
      "rec.sport.hockey rec.sport.hockey\n",
      "sci.med sci.med\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "\n",
    "# sample some of the predictions against the ground truths \n",
    "for prediction, truth in zip(predicted[:10], y_test[:10]):\n",
    "    print(prediction, truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some legit evaluation. The `classification_report()` function gives you precison, recall and f1 scores for each label, and their average. If you want to calculate overall macro-averaged, micro-averaged or weighted performance, you can use the `precision_recall_fscore_support`. Finally, the `confusion_matrix()` can show you which labels are confusing to the model, but unfortunately, it does not include the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.91      0.87      0.89       164\n",
      "           comp.graphics       0.54      0.86      0.67       185\n",
      " comp.os.ms-windows.misc       0.86      0.10      0.18       184\n",
      "comp.sys.ibm.pc.hardware       0.71      0.77      0.74       222\n",
      "   comp.sys.mac.hardware       0.87      0.82      0.85       171\n",
      "          comp.windows.x       0.73      0.86      0.79       192\n",
      "            misc.forsale       0.96      0.62      0.76       213\n",
      "               rec.autos       0.87      0.92      0.89       201\n",
      "         rec.motorcycles       0.97      0.96      0.96       183\n",
      "      rec.sport.baseball       0.95      0.93      0.94       196\n",
      "        rec.sport.hockey       0.97      0.97      0.97       213\n",
      "               sci.crypt       0.83      0.97      0.89       202\n",
      "         sci.electronics       0.89      0.82      0.85       206\n",
      "                 sci.med       0.94      0.92      0.93       203\n",
      "               sci.space       0.92      0.96      0.94       203\n",
      "  soc.religion.christian       0.71      0.99      0.83       175\n",
      "      talk.politics.guns       0.85      0.95      0.90       177\n",
      "   talk.politics.mideast       0.86      0.97      0.91       178\n",
      "      talk.politics.misc       0.79      0.88      0.84       172\n",
      "      talk.religion.misc       0.97      0.48      0.64       126\n",
      "\n",
      "             avg / total       0.86      0.84      0.82      3766\n",
      "\n",
      "Micro-averaged Performance:\n",
      "Precision: 0.8369622942113648, Recall: 0.8369622942113648, F1: 0.8369622942113648\n",
      "[[143   0   0   0   0   0   0   1   0   0   0   0   0   0   0  12   0   5\n",
      "    1   2]\n",
      " [  0 159   0   6   0   7   1   0   0   0   0   1   1   1   3   2   0   1\n",
      "    3   0]\n",
      " [  0  58  18  37   4  43   0   2   0   1   0  11   1   0   2   1   0   0\n",
      "    6   0]\n",
      " [  0  13   0 172  10   6   2   0   0   0   0   7   6   2   0   1   2   0\n",
      "    1   0]\n",
      " [  0  11   1   6 141   2   1   0   0   0   0   2   4   0   0   1   0   1\n",
      "    1   0]\n",
      " [  0  17   1   1   1 165   0   0   0   1   0   2   0   1   0   1   1   1\n",
      "    0   0]\n",
      " [  0   8   0  14   5   0 133  19   2   3   2   2   7   4   1   0   3   3\n",
      "    7   0]\n",
      " [  0   1   0   0   0   0   2 185   3   1   0   2   1   1   0   0   2   1\n",
      "    2   0]\n",
      " [  0   0   0   0   0   0   0   3 175   0   0   1   0   0   0   1   0   2\n",
      "    1   0]\n",
      " [  0   0   0   0   1   0   0   1   0 183   4   0   0   0   1   4   1   1\n",
      "    0   0]\n",
      " [  0   2   0   1   0   0   0   0   0   0 207   0   0   0   0   0   1   1\n",
      "    1   0]\n",
      " [  0   5   0   0   0   0   0   0   0   0   0 195   0   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0  11   0   5   0   0   0   2   0   1   0  10 168   1   6   1   0   0\n",
      "    1   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   1   0 186   2  10   0   0\n",
      "    1   0]\n",
      " [  0   1   0   0   0   1   0   0   0   0   0   0   1   0 195   0   1   1\n",
      "    3   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0 173   0   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0 169   1\n",
      "    6   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3   1 173\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   2   0   2   0   0   1   3   5   6\n",
      "  152   0]\n",
      " [ 14   1   0   0   0   1   0   0   0   1   0   0   0   1   0  29  11   3\n",
      "    5  60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, labels=dataset.label.unique()))\n",
    "\n",
    "p, r, f1, _ = metrics.precision_recall_fscore_support(y_test, predicted, labels=dataset.label.unique(), average='micro')\n",
    "\n",
    "print(\"Micro-averaged Performance:\\nPrecision: {0}, Recall: {1}, F1: {2}\".format(p, r, f1))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, predicted, labels=dataset.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing & Feature Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One may ask, \"how do I remove stop words, tokenize the texts differently, or use bigrams/trigrams as features?\" \n",
    "The answer is you can do all that when you initialize a [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) object, i.e. you can pass various arguments to the constructor. \n",
    "\n",
    "Here are some of them: `ngram_range` takes in a tuple (n_min, n_max). For example, `(2,2)` means only use bigrams, and `(1,3)` means use unigrams, bigrams, and trigrams. `stop_words` takes in a list of stopwords that you'd like to remove. If you want to use default stopword list in scikit-learn, pass in the string `'english'`. `tokenizer` is a function that takes in a string and returns a string, inside that function, you can define how to tokenize your text. By default, scikit-learn tokenization pattern is `u'(?u)\\b\\w\\w+\\b'`. Finally, `preprocessor` takes in a function of which the argument is a string and the output is a string. You can use it to perform more customized preprocessing. For more detail, please checkout the documentation for `CountVectorizer` or `TfidfVectorizer`.\n",
    "\n",
    "Let's start with defining a preprocessor to normalize all the numeric values, i.e. replacing numbers with the string `NUM`. Then, we construct a new `CountVectorizer`, and then use unigrams, bigrams, and trigrams as features, and remove stop words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_numbers(s):\n",
    "    return re.sub(r'\\b\\d+\\b', 'NUM', s)\n",
    "\n",
    "cv = CountVectorizer(preprocessor=normalize_numbers, ngram_range=(1,3), stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit and transform the train data and transform the test data. The speed of preprocessing and feature extraction depends on the running time of each step. For example, the running time of stopword removal is O(N * M), where N is the vocabulary size of the document, and M is the stopword list size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e1af5abe2e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the raw data into the vectorizer and tranform it into a series of arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/justinso/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 839\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/justinso/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the raw data into the vectorizer and tranform it into a series of arrays\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_test_counts = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Naive Bayes classifier to train a new model and see if it works better. From the last section with out preprocessing or feature engineering, our precison, recall and F1 are in the mid 80s, but now we got 90 for each score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.89      0.94      0.91       152\n",
      "           comp.graphics       0.72      0.90      0.80       188\n",
      " comp.os.ms-windows.misc       0.87      0.80      0.83       205\n",
      "comp.sys.ibm.pc.hardware       0.82      0.87      0.84       189\n",
      "   comp.sys.mac.hardware       0.98      0.82      0.89       199\n",
      "          comp.windows.x       0.89      0.90      0.89       202\n",
      "            misc.forsale       0.89      0.78      0.83       193\n",
      "               rec.autos       0.96      0.92      0.94       194\n",
      "         rec.motorcycles       0.97      0.95      0.96       180\n",
      "      rec.sport.baseball       0.97      0.92      0.95       209\n",
      "        rec.sport.hockey       0.83      0.98      0.90       186\n",
      "               sci.crypt       0.92      0.96      0.94       193\n",
      "         sci.electronics       0.96      0.86      0.90       208\n",
      "                 sci.med       0.96      0.94      0.95       202\n",
      "               sci.space       0.94      0.96      0.95       206\n",
      "  soc.religion.christian       0.90      0.95      0.93       211\n",
      "      talk.politics.guns       0.90      0.98      0.94       174\n",
      "   talk.politics.mideast       0.90      0.99      0.95       182\n",
      "      talk.politics.misc       0.95      0.92      0.93       164\n",
      "      talk.religion.misc       0.93      0.66      0.77       129\n",
      "\n",
      "             avg / total       0.91      0.90      0.90      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "print(metrics.classification_report(y_test, predicted, labels=dataset.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember there are other vecotrizers that you can use? Walla, one of them is `TfidfVecotrizer`. LOL, what is tf-idf? It's on [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf). It basically reflects how important a word/phrase is to a document in a corpus. The constructor of `TfidfVectorizer` takes in the same parameters as that of `CountVectorizer`, so you can perfrom the same preprocessing/feature extraction. Try to run the following block of code and see if using tf-idf will help improve the performance. There are some other parameters in the constructor that you can tweak when initializing the object, and they could affect the performance as well.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.93      0.84      0.88       164\n",
      "           comp.graphics       0.80      0.75      0.77       185\n",
      " comp.os.ms-windows.misc       0.76      0.88      0.81       184\n",
      "comp.sys.ibm.pc.hardware       0.84      0.77      0.80       222\n",
      "   comp.sys.mac.hardware       0.91      0.83      0.87       171\n",
      "          comp.windows.x       0.91      0.84      0.87       192\n",
      "            misc.forsale       0.93      0.72      0.81       213\n",
      "               rec.autos       0.87      0.93      0.90       201\n",
      "         rec.motorcycles       0.94      0.96      0.95       183\n",
      "      rec.sport.baseball       0.94      0.91      0.93       196\n",
      "        rec.sport.hockey       0.96      0.99      0.97       213\n",
      "               sci.crypt       0.88      0.97      0.92       202\n",
      "         sci.electronics       0.92      0.82      0.87       206\n",
      "                 sci.med       0.95      0.84      0.89       203\n",
      "               sci.space       0.92      0.95      0.93       203\n",
      "  soc.religion.christian       0.48      0.98      0.64       175\n",
      "      talk.politics.guns       0.89      0.98      0.94       177\n",
      "   talk.politics.mideast       0.89      0.98      0.93       178\n",
      "      talk.politics.misc       0.99      0.73      0.84       172\n",
      "      talk.religion.misc       1.00      0.35      0.52       126\n",
      "\n",
      "             avg / total       0.88      0.86      0.86      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(preprocessor=normalize_numbers, ngram_range=(1,3), stop_words='english')\n",
    "X_train_tf = tv.fit_transform(X_train)\n",
    "X_test_tf = tv.transform(X_test)\n",
    "clf2 = MultinomialNB().fit(X_train_tf, y_train)\n",
    "predicted = clf2.predict(X_test_tf)\n",
    "print(metrics.classification_report(y_test, predicted, labels=dataset.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you like typing a longer block of code, you can use the `TfidfTransformer` to transform a word count matrix created by `CountVectorizer` into a tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Selection\n",
    "\n",
    "Depending on the size of your data and the nature your task, some classifiers might perform better than others. These days, Maximum Entropy is a very popular classifier for many machine learning tasks. So let's try the [logistic regression classifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) in scikit-learn (Maxent and logistic regression are virtually the same thing). Please note that this classifier is a lot slower than Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.92      0.93      0.92       164\n",
      "           comp.graphics       0.76      0.78      0.77       185\n",
      " comp.os.ms-windows.misc       0.83      0.83      0.83       184\n",
      "comp.sys.ibm.pc.hardware       0.78      0.77      0.78       222\n",
      "   comp.sys.mac.hardware       0.81      0.85      0.83       171\n",
      "          comp.windows.x       0.85      0.79      0.82       192\n",
      "            misc.forsale       0.86      0.86      0.86       213\n",
      "               rec.autos       0.85      0.94      0.89       201\n",
      "         rec.motorcycles       0.97      0.94      0.95       183\n",
      "      rec.sport.baseball       0.94      0.95      0.95       196\n",
      "        rec.sport.hockey       0.97      0.98      0.97       213\n",
      "               sci.crypt       0.95      0.95      0.95       202\n",
      "         sci.electronics       0.86      0.84      0.85       206\n",
      "                 sci.med       0.92      0.94      0.93       203\n",
      "               sci.space       0.93      0.98      0.95       203\n",
      "  soc.religion.christian       0.90      0.95      0.93       175\n",
      "      talk.politics.guns       0.95      0.93      0.94       177\n",
      "   talk.politics.mideast       0.96      0.95      0.95       178\n",
      "      talk.politics.misc       0.91      0.85      0.88       172\n",
      "      talk.religion.misc       0.91      0.76      0.83       126\n",
      "\n",
      "             avg / total       0.89      0.89      0.89      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for the sake of speed, we will just use all the default value of the constructor\n",
    "cv = CountVectorizer()\n",
    "X_train_counts = cv.fit_transform(X_train)\n",
    "X_test_counts = cv.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear', max_iter=500, n_jobs=4)\n",
    "clf.fit(X_train_counts, y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "print(metrics.classification_report(y_test, predicted, labels=dataset.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are many other supervised, semi-supervised and clustering classifiers, and many of them work almost the same: (1) initialize a classifier, (2) fit the feature matrix and truths of the train set, and (3) pass in the feature matrix of test set to perform prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
